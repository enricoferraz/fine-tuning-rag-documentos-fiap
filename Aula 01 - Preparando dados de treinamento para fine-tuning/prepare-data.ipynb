{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMsfekl3GPGVmtH1xIU0yL7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#Conexão com o Google Drive\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"ZRRzGpR0av3o"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VvXIUylQYIEr"},"outputs":[],"source":["import json\n","\n","def process_line_complementary_dataset(item):\n","    #Processa cada linha do arquivo JSON Lines, que contém os campos 'story' e 'summary\n","    return {\n","        \"input\": f\"SUMMARIZE THIS NEWS.\\n[|News|] {item['story']}[|eNews|]\\n\\n[|summary|]{item['summary']}[|esummary|]\"\n","    }\n","\n","def process_news_summaries_file(file_path, processed_data):\n","    #Lê um arquivo JSON do nosso dataset, processa cada notícia para formatar conforme o solicitado e adiciona à lista processed_data\n","    with open(file_path, 'r', encoding='utf-8') as file:\n","        json_data = json.load(file)\n","        news_list = json_data[\"news_summaries\"]\n","\n","        for item in news_list:\n","            story = item[\"story\"]\n","            summary = item[\"summary\"]\n","            formatted_text = f\"SUMMARIZE THIS NEWS.\\n[|News|] {story}[|eNews|]\\n\\n[|summary|]{summary}[|esummary|]\"\n","            processed_data.append({\"input\": formatted_text})\n"]},{"cell_type":"code","source":["\n","# Lista para armazenar todos os dados processados\n","processed_data = []\n","\n","# Processar dados do arquivo JSON Lines do dataset complementar\n","with open(r'data.jsonl', 'r', encoding='utf-8') as file:\n","    for line in file:\n","        item = json.loads(line)\n","        processed_data.append(process_line_complementary_dataset(item))\n","\n","# Adicionar dados processados do arquivo JSON regular à mesma lista\n","process_news_summaries_file(r'news_summaries.json', processed_data)\n","\n","# Salvar todos os dados processados em um arquivo JSON\n","output_filename = r'news_dataset_chat_data.json'\n","with open(output_filename, 'w', encoding='utf-8') as file:\n","    json.dump(processed_data, file, ensure_ascii=False, indent=4)\n","\n","print(f\"Todos os dados reformatados foram salvos em '{output_filename}'.\")\n"],"metadata":{"id":"9dF4NkQmZqv1"},"execution_count":null,"outputs":[]}]}